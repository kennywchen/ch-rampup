{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kennywchen/ch-rampup/blob/main/data_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEX1de0y9MBB"
      },
      "outputs": [],
      "source": [
        "# had issues running locally so using Colab Notebook\n",
        "\n",
        "!pip install ydata-synthetic==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxwlKnmM7G1O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.jit\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from collections import defaultdict\n",
        "from ydata_synthetic.synthesizers.regular import RegularSynthesizer\n",
        "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
        "\n",
        "\n",
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, X, y, model_parameters):\n",
        "        self.sample_count = X.shape[0]\n",
        "        self.num_X = torch.tensor(X[:, model_parameters.num_features_idxs].astype(np.float32))\n",
        "        self.cat_X = torch.tensor(X[:, model_parameters.cat_features_idxs].astype(np.int64))\n",
        "        self.emb_X = torch.tensor(X[:, model_parameters.emb_features_idxs].astype(np.float32))\n",
        "        self.y = torch.as_tensor(y.astype(np.float32))\n",
        "        self.model_parameters = model_parameters\n",
        "\n",
        "    def shuffle_and_transfer(self):\n",
        "        p = np.random.permutation(self.sample_count)\n",
        "        self.num_X_dev = torch.as_tensor(self.num_X[p])\n",
        "        self.cat_X_dev = torch.as_tensor(self.cat_X[p])\n",
        "        self.emb_X_dev = torch.as_tensor(self.emb_X[p])\n",
        "        self.y_dev = torch.as_tensor(self.y[p])\n",
        "\n",
        "    def __len__(self):\n",
        "        return int((self.sample_count + self.model_parameters.BATCH_SIZE - 1) / self.model_parameters.BATCH_SIZE)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.model_parameters.BATCH_SIZE\n",
        "        if start + self.model_parameters.BATCH_SIZE < self.sample_count:\n",
        "            return [\n",
        "                self.num_X_dev[start : start + self.model_parameters.BATCH_SIZE],\n",
        "                self.cat_X_dev[start : start + self.model_parameters.BATCH_SIZE],\n",
        "                self.emb_X_dev[start : start + self.model_parameters.BATCH_SIZE],\n",
        "                self.y_dev[start : start + self.model_parameters.BATCH_SIZE],\n",
        "            ]\n",
        "        else:\n",
        "            return [self.num_X_dev[start:], self.cat_X_dev[start:], self.emb_X_dev[start:], self.y_dev[start:]]\n",
        "\n",
        "\n",
        "class ModelParameters2(object):\n",
        "    def __init__(self):\n",
        "        self.BATCH_SIZE = 128 * 1024\n",
        "        self.NUMERIC_FEATURES_COUNT = 4\n",
        "        self.CATEGORICAL_FEATURES_COUNT = 2\n",
        "        self.EMBEDDING_DIM_0 = 4\n",
        "        self.EMBEDDING_DIM_1 = 2\n",
        "        self.EMBEDDING_FEATURES_COUNT = self.EMBEDDING_DIM_0 + self.EMBEDDING_DIM_1\n",
        "        self.SAMPLES = 1 * self.BATCH_SIZE\n",
        "        self.NUM_FEATURE_START = 0\n",
        "        self.CAT_FEATURE_START = self.NUMERIC_FEATURES_COUNT\n",
        "        self.EMB_FEATURE_START = self.CAT_FEATURE_START + self.CATEGORICAL_FEATURES_COUNT\n",
        "        self.TOTAL_COLUMNS = self.EMB_FEATURE_START + self.EMBEDDING_DIM_0 + self.EMBEDDING_DIM_1\n",
        "        self.num_features_idxs = list(range(0, self.NUMERIC_FEATURES_COUNT))\n",
        "        self.cat_features_idxs = list(range(self.CAT_FEATURE_START, self.EMB_FEATURE_START))\n",
        "        self.emb_features_idxs = list(range(self.EMB_FEATURE_START, self.TOTAL_COLUMNS))\n",
        "\n",
        "\n",
        "class ToyModel(nn.Module):\n",
        "    def __init__(self, model_parameters):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnt_num_dim = model_parameters.NUMERIC_FEATURES_COUNT\n",
        "        self.cnt_cat_emb_dim = sum([3] * model_parameters.CATEGORICAL_FEATURES_COUNT)\n",
        "        self.cnt_emb_dim = model_parameters.EMBEDDING_FEATURES_COUNT\n",
        "        self.num_bn_layer = nn.BatchNorm1d(self.cnt_num_dim)\n",
        "        self.emb_layers = nn.ModuleList([nn.Embedding(1000, 3) for f in model_parameters.cat_features_idxs])\n",
        "        self.sequence = nn.Sequential(\n",
        "            nn.Linear(self.cnt_num_dim + self.cnt_cat_emb_dim + self.cnt_emb_dim, 50),\n",
        "            nn.BatchNorm1d(50),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 10),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, num_x, cat_x, emb_x):\n",
        "        normalized_cont_data = self.num_bn_layer(num_x)\n",
        "        arr0 = self.emb_layers[0] # nn.embedding(10, 3) -> range (0-9) 3 dimensions\n",
        "        cat = cat_x[:, 0] # one column of the categorical variables len sample size\n",
        "        arr00 = arr0(cat) # some 3d array\n",
        "\n",
        "        cat_emb_op = torch.cat([emb_layer(cat_x[:, i]) for i, emb_layer in enumerate(self.emb_layers)], dim=1)\n",
        "        x = torch.cat([normalized_cont_data, cat_emb_op, emb_x], dim=1)\n",
        "        x = self.sequence(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "'''\n",
        "Function to test. Saves model. Will be saved by MLEs.\n",
        "'''\n",
        "def save_model(model_name, dataset):\n",
        "    # model.eval()\n",
        "\n",
        "    num_x, cat_x, emb_x, y = dataset[0]\n",
        "    input = (num_x, cat_x, emb_x)\n",
        "    model_parameters = ModelParameters2()\n",
        "    toy_model = ToyModel(model_parameters).float()\n",
        "    traced_model = torch.jit.trace(toy_model, input)\n",
        "    traced_model.save(model_name)\n",
        "    print(\"saved\")\n",
        "\n",
        "\n",
        "'''\n",
        "training data\n",
        "features 1-2 are normal\n",
        "features 3-5 are skewed\n",
        "'''\n",
        "def long_tail_dataset(sample_size):\n",
        "    f1 = np.random.normal(15, 10, sample_size)\n",
        "    f2 = np.random.normal(-100, 3, sample_size)\n",
        "    f3 = np.random.exponential(scale = 1, size=sample_size)\n",
        "    f4 = np.random.poisson(lam = 5, size = sample_size)\n",
        "    f5= np.random.exponential(scale = 2, size = sample_size)\n",
        "    f6 = np.random.normal(5, 2, sample_size)\n",
        "    f7 = np.random.normal(4, 1.5, sample_size)\n",
        "    f8 = np.random.exponential(scale = .5, size = sample_size)\n",
        "    f9 = np.random.poisson(lam = 2, size = sample_size)\n",
        "    f10 = np.random.poisson(lam = 1, size = sample_size)\n",
        "    f11 = np.random.poisson(lam = 2, size = sample_size)\n",
        "    f12 = np.random.poisson(lam = 1, size = sample_size)\n",
        "\n",
        "    features = [f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12]\n",
        "\n",
        "    for i in range(4, 12):\n",
        "        features[i] = [int(min(10, max(0, f))) for f in features[i]]\n",
        "\n",
        "    data = np.transpose(np.array(features))\n",
        "    return torch.from_numpy(data)\n",
        "\n",
        "\n",
        "\n",
        "#### above functions are solely for testing purposes ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiH7cX9e7HOC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdFj-pRZ7HVn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0FIA9ubA8dv",
        "outputId": "a8ac06e7-d8ee-4b19-fae9-14ebeefb6406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Long Tails at features: [2]\n",
            "Long Tail Test For Feature: 2\n",
            "Epoch: 0 | critic_loss: 5.42899751663208 | generator_loss: 2.126983880996704\n",
            "saved\n",
            "\n",
            "Synthetic Test Results: \n",
            "Success:  0 / 10\n",
            "Average Output:  0.16092152297496795\n",
            "Average Output SD:  0.36658636764455316\n",
            "Average Range of Valid Outputs:  [-0.4956326484680176, 0.4982394605875015]\n",
            "\n",
            "Fails: \n",
            "Tests:  ['Test 0', 'Test 1', 'Test 2', 'Test 3', 'Test 4', 'Test 5', 'Test 6', 'Test 7', 'Test 8', 'Test 9']\n",
            "Average Range of Failed Outputs (Lower):  [-0.354541015625, -0.14477730478559223]\n",
            "Average Range of Failed Outputs (Upper):  [0.0325180675302233, 0.10247236335432375]\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:1093: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Tensor-likes are not close!\n",
            "\n",
            "Mismatched elements: 1000 / 1000 (100.0%)\n",
            "Greatest absolute difference: 1.386189341545105 at index (360, 0) (up to 1e-05 allowed)\n",
            "Greatest relative difference: 273.45195752862014 at index (83, 0) (up to 1e-05 allowed)\n",
            "  _check_trace(\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "@param data (Pytorch Tensor)\n",
        "@param model_parameters (ModelParameters2)\n",
        "Creates similarly distributed synthetic dataset\n",
        "'''\n",
        "def synth_data_gen2(data, model_parameters):\n",
        "\n",
        "  temp = data.numpy()\n",
        "  data = pd.DataFrame(temp)\n",
        "\n",
        "  num_cols = [f'num_{i}' for i in model_parameters.num_features_idxs]\n",
        "  cat_cols = [f'cat_{i}' for i in model_parameters.cat_features_idxs]\n",
        "  emb_cols = [f'emb_{i}' for i in model_parameters.emb_features_idxs]\n",
        "\n",
        "  names = num_cols + cat_cols + emb_cols\n",
        "\n",
        "  new_names = {}\n",
        "\n",
        "  for i, n in enumerate(names):\n",
        "    new_names[i] = n\n",
        "\n",
        "  data.rename(columns = new_names, inplace=True)\n",
        "\n",
        "  batch_size = 500\n",
        "  epochs = 1\n",
        "  learning_rate = 2e-4\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.9\n",
        "  ctgan_args = ModelParameters(batch_size=batch_size,\n",
        "                            lr=learning_rate,\n",
        "                            betas=(beta_1, beta_2))\n",
        "  train_args = TrainParameters(epochs=epochs)\n",
        "  synth = RegularSynthesizer(modelname='ctgan', model_parameters=ctgan_args)\n",
        "  synth.fit(data=data, train_arguments=train_args, num_cols=num_cols, cat_cols=cat_cols + emb_cols)\n",
        "  synth_data = synth.sample(1000)\n",
        "\n",
        "  return synth_data\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "@param model_name (String)\n",
        "@param torch_dataset (Tabular Dataset)\n",
        "@param model_parameters (ModelParameters2 Object)\n",
        "Performs generates synthetic data + runs test\n",
        "'''\n",
        "# runs synthetic data test on given dataset\n",
        "def y_data_synth_test(model_name, model_parameters, expected_range, dataset):\n",
        "\n",
        "  #1. load model-- COMMENT FOR TESTING\n",
        "  model = torch.jit.load(model_name)\n",
        "\n",
        "  y_data_temp = synth_data_gen2(dataset, model_parameters)\n",
        "  synth_dataset = y_data_temp.values\n",
        "\n",
        "  rows = synth_dataset.shape[0]\n",
        "  y = np.random.uniform(low = 0, high = 0, size = (rows, 1))\n",
        "\n",
        "  tab_data = TabularDataset(synth_dataset, y, model_parameters)\n",
        "  tab_data.shuffle_and_transfer()\n",
        "\n",
        "  #### TESTING PURPOSES ####\n",
        "  # save_model(model_name, tab_data)\n",
        "\n",
        "  # model = torch.jit.load(model_name)\n",
        "  ##########################\n",
        "\n",
        "  gather_test_stats(model, tab_data, expected_range)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "@param model (Loaded in Model)\n",
        "@param tab_data (Tabular Dataset)\n",
        "@param exp_range (List)\n",
        "Gathers statistics for each iteration of running the model\n",
        "'''\n",
        "def gather_test_stats(model, tab_data, exp_range):\n",
        "  testingIterations = 10\n",
        "  numSuccess = 0\n",
        "  succeeded = []\n",
        "  averages = []\n",
        "  sds = []\n",
        "  errors = {}\n",
        "  errorValues = {}\n",
        "  avgSuccessRangeLower = []\n",
        "  avgSuccessRangeUpper = []\n",
        "  avgFailLowerL = []\n",
        "  avgFailUpperL = []\n",
        "  avgFailLowerU = []\n",
        "  avgFailUpperU = []\n",
        "\n",
        "  for i in range(testingIterations):\n",
        "      res, output, sRange, fRangeL, fRangeU, upperFails, lowerFails = run_model(model, tab_data, exp_range)\n",
        "      avgSuccessRangeLower.append(sRange[0])\n",
        "      avgSuccessRangeUpper.append(sRange[1])\n",
        "      avgFailLowerL.append(fRangeL[0])\n",
        "      avgFailUpperL.append(fRangeL[1])\n",
        "      avgFailLowerU.append(fRangeU[0])\n",
        "      avgFailUpperU.append(fRangeU[1])\n",
        "      averages.append(torch.mean(output).item())\n",
        "      sds.append(np.std(output.tolist()))\n",
        "      if res:\n",
        "          numSuccess += 1\n",
        "          succeeded.append(i)\n",
        "      else:\n",
        "          errors[\"Test \" + str(i)] = output\n",
        "\n",
        "  print()\n",
        "  print(\"Synthetic Test Results: \")\n",
        "  print(\"Success: \", numSuccess, \"/\", testingIterations)\n",
        "  print(\"Average Output: \", np.mean(averages))\n",
        "  print(\"Average Output SD: \", np.mean(sds))\n",
        "  print(\"Average Range of Valid Outputs: \", [np.sum(avgSuccessRangeLower) / testingIterations, np.sum(avgSuccessRangeUpper) / testingIterations])\n",
        "\n",
        "  if not errors:\n",
        "      print(\"Errors: None\")\n",
        "  else:\n",
        "      print()\n",
        "      print(\"Fails: \")\n",
        "      print(\"Tests: \", [key for key in errors])\n",
        "      print(\"Average Range of Failed Outputs (Lower): \", [np.sum(avgFailLowerL) / max(lowerFails, 1), np.sum(avgFailUpperL) / max(lowerFails, 1)])\n",
        "      print(\"Average Range of Failed Outputs (Upper): \", [np.sum(avgFailLowerU) / max(upperFails, 1), np.sum(avgFailUpperU) / max(upperFails, 1)])\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "@param model (Loaded in Model)\n",
        "@param torch_dataset (Tabular Dataset)\n",
        "@param model_parameters (ModelParameters2 Object)\n",
        "Takes in a loaded model. Runs model according to model parameters\n",
        "'''\n",
        "def run_model(model, torch_dataset, expected_range):\n",
        "  torch_dataset.shuffle_and_transfer()\n",
        "  num_x, cat_x, emb_x, y = torch_dataset[0]\n",
        "\n",
        "\n",
        "  pred = model(num_x, cat_x, emb_x)\n",
        "\n",
        "  successRange = [float('inf'), -float('inf')]\n",
        "  failRangeLower = [float('inf'), -float('inf')]\n",
        "  failRangeUpper = [float('inf'), -float('inf')]\n",
        "  numLowerFail = 0\n",
        "  numUpperFail = 0\n",
        "  success = True\n",
        "\n",
        "  for i in range(pred.shape[0]):\n",
        "      value = pred[i][0].item()\n",
        "      if value < expected_range[0] or value > expected_range[1]:\n",
        "\n",
        "          if value < expected_range[0]:\n",
        "              failRangeLower[0] = min(failRangeLower[0], value)\n",
        "              failRangeLower[1] = max(failRangeLower[1], value)\n",
        "              numLowerFail += 1\n",
        "          elif value > expected_range[1]:\n",
        "              failRangeUpper[0] = min(failRangeUpper[0], value)\n",
        "              failRangeUpper[1] = max(failRangeUpper[1], value)\n",
        "              numUpperFail += 1\n",
        "          success = False\n",
        "      else:\n",
        "          successRange[0] = min(successRange[0], value)\n",
        "          successRange[1] = max(successRange[1], value)\n",
        "\n",
        "  if failRangeLower == [float('inf'), -float('inf')]:\n",
        "      failRangeLower = [0, 0]\n",
        "\n",
        "  if failRangeUpper == [float('inf'), -float('inf')]:\n",
        "      failRangeUpper = [0, 0]\n",
        "\n",
        "  if successRange == [float('inf'), -float('inf')]:\n",
        "      success = [0, 0]\n",
        "\n",
        "  return success, pred, successRange, failRangeLower, failRangeUpper, numUpperFail, numLowerFail\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "@param model_name (String)\n",
        "@param model_parameters (ModelParameters2() Object)\n",
        "@param expected_range (List)\n",
        "@param dataset (Pytorch Tensor)\n",
        "Checks for long tails within given dataset and performs synthetic data test on any long tails\n",
        "'''\n",
        "def long_tail_test(model_name, model_parameters, expected_range, dataset):\n",
        "\n",
        "  rows = dataset.shape[0]\n",
        "  num_numerical = model_parameters.NUMERIC_FEATURES_COUNT\n",
        "  bin_num = 20\n",
        "  long_tails = {}\n",
        "\n",
        "  #look for tails\n",
        "  for i in range(num_numerical):\n",
        "    column = dataset[:, i]\n",
        "    numpy_col = column.numpy()\n",
        "    ___, bin_edges = np.histogram(numpy_col, bins=bin_num)\n",
        "    tail_value = np.percentile(column, 99)\n",
        "    bin_val = pd.cut([tail_value], bin_edges)[0].left\n",
        "\n",
        "    bin = np.where(np.round(bin_edges, decimals=3) == bin_val)[0][0]\n",
        "    threshold_percentage = 0.2\n",
        "\n",
        "    if bin_num - bin > threshold_percentage * bin_num:\n",
        "        long_tails[i] = [tail_value, max(column).item()]\n",
        "\n",
        "  print(\"Detected Long Tails at features: \" + str(list(long_tails.keys())))\n",
        "\n",
        "  for col in long_tails:\n",
        "    print(f\"Long Tail Test For Feature: {col}\")\n",
        "    filtered_long_data = dataset[dataset[:, col] >= long_tails[col][0]]\n",
        "\n",
        "    y_data_synth_test(model_name, model_parameters,[-0.5, 0.5], dataset)\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "@param model_name (String)\n",
        "@param dataset (Pytorch Tensor)\n",
        "@param expected_range (List)\n",
        "Splits given dataset into validation and training and performs test on validation\n",
        "'''\n",
        "def validation_data_test(model_name, dataset, expected_range):\n",
        "\n",
        "  model = torch.jit.load(model_name)\n",
        "\n",
        "  validation_data, training_data = torch.utils.data.random_split(dataset, [0.2, 0.8])\n",
        "  gather_test_stats(model, validation_data, expected_range)\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "@param model_name (String)\n",
        "@param model_parameters (ModelParameters2() Object)\n",
        "@param expected_range (List)\n",
        "Performs a data test using a uniform wide range of values\n",
        "'''\n",
        "def uniform_synth_data_test(model_name, model_parameters, expected_range):\n",
        "\n",
        "  #1. load model COMMENT FOR TESTING\n",
        "  model = torch.jit.load(model_name)\n",
        "\n",
        "  # 2. use model config to count the number of numerical, categorical, and embeding features\n",
        "  numNumerical = model_parameters.NUMERIC_FEATURES_COUNT\n",
        "  numCategorical = model_parameters.CATEGORICAL_FEATURES_COUNT\n",
        "\n",
        "  numEmbedding = model_parameters.EMBEDDING_FEATURES_COUNT\n",
        "\n",
        "  totalCols = numNumerical + numCategorical + numEmbedding\n",
        "\n",
        "  # 3. create a range of data to test on as well as determine # of samples to take\n",
        "  lower, upper = -float(1000000000), float(1000000000)\n",
        "\n",
        "  #specify ranges instead of default [0,1) -> pass into TabularDataset constructor\n",
        "  NUM_SAMPLES = 128 * 1024\n",
        "\n",
        "\n",
        "  # SET TO 10 FOR TESTING\n",
        "  embedding_num = len(model.state_dict()['emb_layers.0.weight']) # vocabulary size of cat variables\n",
        "\n",
        "  # 4. create sample inputs NUM_SAMPLES times\n",
        "  X = np.array([]).reshape(0, totalCols)\n",
        "  for _ in range(NUM_SAMPLES):\n",
        "      num = np.random.uniform(low = lower, high = upper, size = (1,numNumerical))\n",
        "      cat = np.random.uniform(low = 0, high = embedding_num, size = (1,numCategorical))\n",
        "      embed = np.random.uniform(low = lower, high = upper, size = (1,numEmbedding))\n",
        "\n",
        "      X = np.append(X, np.hstack((num, cat, embed)), axis = 0)\n",
        "\n",
        "  y = np.random.uniform(low = lower, high = upper, size = (NUM_SAMPLES, 1))\n",
        "\n",
        "  dataset = TabularDataset(X, y, model_parameters)\n",
        "\n",
        "  dataset.shuffle_and_transfer()\n",
        "\n",
        "  #### FOR TESTING PURPOSES ####\n",
        "  # save_model(model_name, dataset)\n",
        "\n",
        "  # model = torch.jit.load(model_name)\n",
        "  ##############################\n",
        "\n",
        "  gather_test_stats(model, dataset, expected_range)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example of using data generation\n",
        "\n",
        "def main_test():\n",
        "\n",
        "  # Example Parameters\n",
        "  model_parameters = ModelParameters2()\n",
        "  model_name = \"model.pt\"\n",
        "  dataset = long_tail_dataset(1000)\n",
        "  expected_range = [-2, 1]\n",
        "\n",
        "\n",
        "\n",
        "  ### Regular Synthetic-Data Test ###\n",
        "  y_data_synth_test(model_name, model_parameters, expected_range, dataset)\n",
        "\n",
        "  ### Long Tails Test ###\n",
        "  long_tail_test(model_name, model_parameters, expected_range, dataset)\n",
        "\n",
        "  ### Random Uniform Data Test ###\n",
        "  uniform_synth_data_test(model_name, model_parameters, expected_range)\n",
        "\n",
        "  ### Validation Test ###\n",
        "  validation_data_test(model_name, dataset, expected_range)\n",
        "\n",
        "\n",
        "main_test()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhfC_xxukSMI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}